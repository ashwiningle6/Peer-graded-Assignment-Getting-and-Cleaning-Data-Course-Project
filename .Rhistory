set.seed(10)
x<-rep(0:1,each=5)
e<-rnorm(10,0,20)
y<-0.5+2*x*e
x
e
y
q()
liibrary(dylrp)
library(dylrp)
packages
?packages
?package
knitr::opts_chunk$set(echo = TRUE, results = "asis")
library(dplyr)
library("dplyr")
install.package("dplyr")
install.packages("dplyr")
install.package(plyr)
install.packages(plyr)
install.package("plyr")
install.packages("plyr")
q()
install_package(dplyr)
install_packages("dplyr")
install_packages(dplyr)
library(dplyr)
swirl()
library(swirl)
swirl()
read.csv()
read.csv(path2csv,stringsAsFactors = FALSE)
mydf<-read.csv(path2csv,stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran<-tb1_df(mydf)
cran<-tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package,
country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
select(cran)
crsn
cran
select(cran, -time)
-5:20
-(5:20)
select(X:suze)
select(X:size)
select(cran,X:size)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version == "3.1.1", country == "IN")
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
filter(cran,is.na(r_version))
is.na(c(3,5,NA,10))
!is.na(c(3,5,NA,10))
filter(cran,!is.na(r_version))
select(cran, ip_id:size)
select(cran, size:ip_id)
cran2<-select(cran, size:ip_id)
arrange(cran2, ip_id).
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange()
arrange(cran2, country (ascending), r_version (descending), ip_id (ascending))
arrange(cran2, country, desc(r_version), ip_id)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb=size_mb/2^10)
mutate(cran3, correct_size)
mutate(cran3, correct_size=(size+1000))
mutate(cran3, correct_size=size+1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
tbl_df()
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by()
?group_by
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package)
summarize(by_package,mean(size))
q()
q()
q()
install.packages("twitteR")
install.packages("ROAuth")
library("ROAuth")
library("twitteR")
download.file(url="http://curl.haxx.se/ca/cacert.pem",destfile="cacert.pem")
cred <- OAuthFactory$new(consumerKey='XXXXXXXXXXXXXXXXXX',
consumerSecret='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
cred <- OAuthFactory$new(consumerKey='XXXXXXXXXXXXXXXXXX',
consumerSecret='XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX',
requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
cred <- OAuthFactory$new(consumerKey='DgVbGaVkEmDNfwX1StlXjdxj9',consumerSecret='0tuImBPgI5WCxSgh21AU4Fq9KISI4GP48Hw6hdiaxQ6dVwQmfi',requestURL='https://api.twitter.com/oauth/request_token',
accessURL='https://api.twitter.com/oauth/access_token',
authURL='https://api.twitter.com/oauth/authorize')
cred$handshake(cainfo="cacert.pem")
save(cred, file="twitter authentication.Rdata")
load("twitter authentication.Rdata")
registerTwitterOAuth(cred)
search.string <- "#nba"
no.of.tweets <- 100
tweets <- searchTwitter(search.string, n=no.of.tweets, cainfo="cacert.pem", lang="en")
tweets
q()
library("swirl")
library("dprk")
get(wd)
gets(wd)
get("wd")
getwd
getwd()
?load
load("getdata%2Fdata%2Fss06hid")
download.file()
download.file(https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
?download.file()
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile="me")
load("me")
load(me)
me
getip
ip
?ip
get(ip)
?get(ip)
ipadd
ipaddr
ipaddress
address
?download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfiel="me1")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",destfile="me1")
q()
install_package("RMySQL")
install_packages("RMySQL")
install.packages("RMySQL")
library("RMySQL")
library("RMySQL")
MySQL
q()
install.packages("DBL")
q()
install_packages("Rfaceook")
install.packages("Rfaceook")
library("Rfaceook")
library("Rfacebook")
install.packages("Rfacebook")
install.packages("Rtwitter")
install.packages(RTtwitter")
install.packages(RTtwitter")
install.packages(RTwitter")
install.packages("RTwitter")
library("RMySQL")
library("DBI")
install.packages("Rinstagram")
install.packages("RInstagram")
install.packages("RGoogle")
install.packages("Rgoogle")
install.packages("Rlinkedin")
install.packages("Rgoogle+")
install.packages("Rgoogleplus")
install.packages("RGoogleplus")
install.packages("RGooglePlus")
install.packages("RGoogle+")
install.packages("RMicrosoft")
install.packages("Rtumblr")
install.packages("RTumblr")
install.packages("Rpinteres")
install.packages("Rpinterest")
install.packages("RPinterest")
install.packages("Rflickr")
install.packages("RFlickr")
install.packages("RReddit")
install.packages("Rreddit")
install.packages("Rqora")
install.packages("Rquora")
install.packages("RQuora")
install.packages("Rvine")
install.packages("Rletterz")
install.packages("Rwattpad")
install.packages("RWattpad")
q()
getwd()
summary("FB-Q4'16-Balance-Sheet")
summary("FB-Q4'16-Balance-Sheet.xslx")
summary(FB-Q4'16-Balance-Sheet)
summary("getdata%2Fdata%2Fss06hid")
?summary
head("getdata%2Fdata%2Fss06hid")
head(getdata%2Fdata%2Fss06hid)
q()
packageVersion("swirl")
install_from_swirl("Getting and Cleaning Data")
swirl()
install_package(swirl)
install_package("swirl"")
q
q()
sad
install_packages("swirl"")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages(swirl)
install.packages("swirl")
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
group_by()
?group_by()
?group_by
by_pacakge()<-group_by(cran)
by_pacakge()<-group_by("cran")
by_pacakge()<-group_by(mydf)
by_pacakge()<-group_by(dplyr)
by_pacakge()<-group_by(.dplyr)
by_pacakge()<-group_by(.mydf)
by_pacakge()<-group_by(.cran)
?group_by
by_pacakge()<-group_by(.cran)
?group_by
by_pacakge()<-group_by(.cran,package)
by_pacakge()<-group_by(tbl_df,package)
by_pacakge()<-group_by(table_df,package)
by_pacakge()<-group_by(.table_df,package)
by_pacakge()<-group_by(.tbl_df,package)
?group_by
by_pacakge()<-group_by(package,.tbl_df)
by_pacakge()<-group_by(package,tbl_df)
skip()
by_pacakge
by_package
summarize(by_package,mean(size))
summarize(by_package,mean(size))
submit()
sumbit()
q()
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
submit()
rbl
tbl
pack_sum
quantile(pack_sum$count,probs=0.99)
top_counts<-filter(count(pack_sum)>679)
top_counts<-filter(pack_sum(count>679))
?filter
top_counts<-filter(pack_sum,count>679)
top_counts
View(top_counts)
?arrange
top_counts_sorted<-arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum,unique>465)
View()
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
?mutate
submit()
?mutate
submit()
submit()
submit()
swirl()
library(tidyr)
students
?gather
gather(students,sex,count,-grade)
students2
?gather
res.consult<-gather(students2,sex_class,count,-grade)
res<-gather(students2,sex_class,count,-grade)
res
?separate
separate(res,sex_class,into=c("sex","class"))
submit()
student3
students3
submit
?grade
?gather
submit()
submit()
?spread
?spread
submit()
submit()
?spread
?gather
?spread
submit()
?spread
submit()
submit()
submit()
skip()
library(readr)
parse_number("class5")
?mutate
parse_number
?parse_number
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
skip()
students4
q()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
passed
failed
?mutate
mutate(passed=status)
skip()
failed<-failed %>% mutate(status="failed")
?bind_rorws
?bind_rows
?bind_rows
packageVersion('dplyr')
bind_rows(passed,failed)
dataset
dataset(sat)
sat
submit()
?separate
submit()
?separate
submit()
?separate
skip()
skip()
Sys.getlocale("LC_TIME")
library(lubricate)
library(lubridate)
help(package=lubridate)
today()
this_day<-today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label=TRUE)
now()
this_moment<-now()
this_moment
minute(this_moment)
ymd("1989-05-17")
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12,1975")
mdy("March 12,1975")
ymd("March 12,1975")
mdy("March 12 1975")
mdy(25081985)
dmy(25081985)
ymd("192012")
ymd("--192012")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms(03:22:14)
hms("03:22:14")
dt2
ymd_hms(dt2)
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
update(this_moment)
this_moment<-update(this_moment)
this_moment<-update()
this_moment<-this_moment(update)
this_moment<-this_moment
this_moment<-update(this_moment,hours=10,minutes=16,seconds=0)
this_moment
now("America,New_York")
nyc<-now("America,New_York")
nyc<-now("America/New_York")
nyc
nyc+days(2)
depart<-nyc + days(2)
depart
update(depart,hours=17,minutes=34)
depart<-update(depart,hours=17,minutes=34)
depart
arrive<- depart+hours(15)+minutes(50)
?with_tz
arrive<-with_tz( "Asia/Hong_Kong")
arrive<-with_tz("Asia/Hong_Kong")
arrive<-with_tz(Asia/Hong_Kong)
arrive<-with_tz(arrive,tzone="Asia/Hong_Kong")
arrive
mdy("June 17,2008",tz="Singapore')
mdy("June 17,2008",tz="Singapore")
 mdy("June 17, 2008", tz = "Singapore")
 mdy("June 17 2008", tz = "Singapore")
 mdy("June 17 2008", tz = "Singapore")
mdy("June 17, 2008", tz = "Singapore") 
last_time<-mdy("June 17, 2008", tz = "Singapore") 
last_time
?interval
how_long<-interval(last_time,arrive)
as.long(how_long)
as.period(how_long)
stopwatch()
quit()
getwd()
filesPath <- "C:/Users/jb/Documents/Analytics course/coursera getting and cleaning data/course project/UCI HAR Dataset"
setwd(filesPath)
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip",method="curl")
###Unzip DataSet to /data directory
unzip(zipfile="./data/Dataset.zip",exdir="./data")
filesPath <- "C:/Users/Ingle/Documents/UCI HAR Dataset"
setwd(filesPath)
if(!file.exists("./data")){dir.create("./data")}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileUrl,destfile="./data/Dataset.zip",method="curl")
unzip(zipfile="./data/Dataset.zip",exdir="./data")
library(dplyr)
library(data.table)
utils:::menuInstallPkgs()
library(tidyr)
dataSubjectTrain <- tbl_df(read.table(file.path(filesPath, "train", "subject_train.txt")))
dataSubjectTest  <- tbl_df(read.table(file.path(filesPath, "test" , "subject_test.txt" )))
# Read activity files
dataActivityTrain <- tbl_df(read.table(file.path(filesPath, "train", "Y_train.txt")))
dataActivityTest  <- tbl_df(read.table(file.path(filesPath, "test" , "Y_test.txt" )))
#Read data files.
dataTrain <- tbl_df(read.table(file.path(filesPath, "train", "X_train.txt" )))
dataTest  <- tbl_df(read.table(file.path(filesPath, "test" , "X_test.txt" )))
alldataSubject <- rbind(dataSubjectTrain, dataSubjectTest)
setnames(alldataSubject, "V1", "subject")
alldataActivity<- rbind(dataActivityTrain, dataActivityTest)
setnames(alldataActivity, "V1", "activityNum")
#combine the DATA training and test files
dataTable <- rbind(dataTrain, dataTest)
# name variables according to feature e.g.(V1 = "tBodyAcc-mean()-X")
dataFeatures <- tbl_df(read.table(file.path(filesPath, "features.txt")))
setnames(dataFeatures, names(dataFeatures), c("featureNum", "featureName"))
colnames(dataTable) <- dataFeatures$featureName
#column names for activity labels
activityLabels<- tbl_df(read.table(file.path(filesPath, "activity_labels.txt")))
setnames(activityLabels, names(activityLabels), c("activityNum","activityName"))
# Merge columns
alldataSubjAct<- cbind(alldataSubject, alldataActivity)
dataTable <- cbind(alldataSubjAct, dataTable)
# Reading "features.txt" and extracting only the mean and standard deviation
dataFeaturesMeanStd <- grep("mean\\(\\)|std\\(\\)",dataFeatures$featureName,value=TRUE) #var name
# Taking only measurements for the mean and standard deviation and add "subject","activityNum"
dataFeaturesMeanStd <- union(c("subject","activityNum"), dataFeaturesMeanStd)
dataTable<- subset(dataTable,select=dataFeaturesMeanStd) 
q()
